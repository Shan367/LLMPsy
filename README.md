# LLMPsy
######If you want to ask questions about the native llama large language model, then you need to deploy ollama locally first 
######If you are testing against openai's large language model then you need to set your keys locally now 
#######for mac/linux:export OPENAI_API_KEY="your_api_key_here" 
#######for windows:setx OPENAI_API_KEY "your_api_key_here" 
