<h1>LLMPsy</h1>

<p>If you want to ask questions about the native llama large language model, then you need to deploy ollama locally first </p>
<p>If you are testing against openai's large language model then you need to set your keys locally now 
for mac/linux:export OPENAI_API_KEY="your_api_key_here" 
for windows:setx OPENAI_API_KEY "your_api_key_here" </p>
<p> The aiPsy is a demo without shuffle which can ask chatgpt and llama </p>
<p>The LLM_Psy is the  the file we want to use   </p>

<P>New ZIP file can analysis the questionnaire in json,and giving you some results</P>
